import os
import shutil
from urllib.request import urlopen
import urllib.request
from urllib import parse
import re
from bs4 import BeautifulSoup
import pandas as pd
import datetime

if os.path.exists('../python/oaislib_org.py'):
    shutil.copy('../python/oaislib_org.py', 'oaislib.py')

import oaislib    
    
def fn_get_clean_text(text):
    text = str(text)
    text = text.replace("\\", "")  # ìœ„ì˜ í‘œí˜„ìœ¼ë¡œ ì—­ìŠ¬ë˜ì‹œê°€ ì œê±°ê°€ ì•ˆë˜ì–´ì„œ ì¶”ê°€í•¨
    text = re.sub('[-=+,#/\?:^â­â˜†ï¼‚ã…£â€™$.,ğŸ’«â€"@ğŸ•º*\"â€»~ğŸ’‰&%ğŸ˜ğŸ¥¶ğŸ¤¬ğŸ’šğŸšâ™¨â˜â™¬ã†!ã…¡ã€\\;_â€˜|\(\)\[\]\<\>`\'â€¦ã€‹`]', '', text)
    return text

#ìœ íŠœë¸Œ ìœ íŠœë¸Œ ì¸ê¸°ë™ì˜ìƒ í˜ì´ì§€ì—ì„œ ì œëª©ì„ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ
def ps2010():
    # I/O
    target_url = "https://www.youtube.com/feed/trending"
    output_filepath = 'output/ps2010/y_keyword.csv'


    prefix = 'ps2010'
    output_dir = 'output/' + prefix
    oaislib.fn_output_dir_gen(output_dir)

    
    #Crawling
    html = urllib.request.urlopen(target_url).read()
    soup = BeautifulSoup(html, 'html.parser')
    #íƒ€ì´í‹€ ê°€ì ¸ì˜¤ê¸° ì´ ì—¬ê¸° ì •ê·œí‘œí˜„ì‹ì´ ê¹”ë”í•˜ê²Œ ì²˜ë¦¬ê°€ ì•ˆë¨..
    pattern = 'title":{.*?}'
    #pattern = 'title":"(.*?)"'
    result_title = re.findall(pattern, str(soup), re.MULTILINE | re.IGNORECASE)
    trend_title = [x[25:-2] for x in result_title]
    print(trend_title)
    print('')

    #íŠ¹ìˆ˜ë¬¸ì ì‚­ì œí•˜ëŠ” í•¨ìˆ˜
    trend_title = fn_get_clean_text(trend_title)
    print(trend_title)

    # ë„ì–´ì“°ê¸° ê¸°ì¤€(ì–´ì ˆ) ë‚˜ëˆ„ê¸°
    y_trend_keywords = trend_title.split()

    ##í•œ ê¸€ìë§Œ ìˆëŠ”ê²½ìš° ì‚­ì œ
    for i in range(len(y_trend_keywords)):
        #print(type(y_trend_keywords[i]))
        if len(y_trend_keywords[i]) <= 1:
            y_trend_keywords[i] = ''

    ##ì§‘í•©í˜•ìœ¼ë¡œ ì¤‘ë³µë¬¸ì ì‚­ì œ í›„ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    my_set = set(y_trend_keywords)
    y_trend_keywords = list(my_set)

    ##ê³µë°±ë¬¸ì ì‚­ì œ
    y_trend_keywords = [x for x in y_trend_keywords if x]

    #ë‚ ì§œ ë„£ê¸°
    trend_keyword_df = pd.DataFrame(columns=['y_keyword','cdate'])
    trend_keyword_df['y_keyword'] = y_trend_keywords

    ## ì¤‘ë³µì œê±° 
    trend_keyword_df.drop_duplicates(inplace=True, subset=['y_keyword'])

    ## ë‚ ì§œ ì¶”ê°€
    today_str = oaislib.fn_get_date_str()
    trend_keyword_df['cdate'] = today_str

    if os.path.isfile(output_filepath):
        print("yes exist")
        previous_df = pd.read_csv(output_filepath)
        output_df = pd.concat([previous_df, trend_keyword_df], axis=0)
        output_df.to_csv(output_filepath, index=False)
    else:
        print('nothing, makemake')
        trend_keyword_df.to_csv(output_filepath, index=False)

if __name__ == '__main__':
    ps2010()
